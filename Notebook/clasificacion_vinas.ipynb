{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\n",
      "0   7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5                                                                                                                     \n",
      "1   7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5                                                                                                                     \n",
      "2  7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;...                                                                                                                     \n",
      "3  11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58...                                                                                                                     \n",
      "4   7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5                                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "# Primero empezaré com el análisis de los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../Data/winequality-red.csv')\n",
    "print(df.head()) #Para ver si está todo bien cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                   Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                   --------------  ----- \n",
      " 0   fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"  1599 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 12.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info()) #Analizo los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes) #Para ver los tipos de datos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "#Por lo que puedo ver están bien los datos y no tenemos valores nulos.. veremos duplicados\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value of 'y' is not the name of a column in 'data_frame'. Expected one of ['fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"'] but received: quality",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mbox(df, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\plotly\\express\\_chart_types.py:666\u001b[0m, in \u001b[0;36mbox\u001b[1;34m(data_frame, x, y, color, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, hover_name, hover_data, custom_data, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, orientation, boxmode, log_x, log_y, range_x, range_y, points, notched, title, template, width, height)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbox\u001b[39m(\n\u001b[0;32m    626\u001b[0m     data_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    655\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    656\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[0;32m    657\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m    In a box plot, rows of `data_frame` are grouped together into a\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m    box-and-whisker mark to visualize their distribution.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    range (IQR: Q3-Q1), see \"points\" for other options.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_figure(\n\u001b[0;32m    667\u001b[0m         args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m(),\n\u001b[0;32m    668\u001b[0m         constructor\u001b[38;5;241m=\u001b[39mgo\u001b[38;5;241m.\u001b[39mBox,\n\u001b[0;32m    669\u001b[0m         trace_patch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(boxpoints\u001b[38;5;241m=\u001b[39mpoints, notched\u001b[38;5;241m=\u001b[39mnotched, x0\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, y0\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    670\u001b[0m         layout_patch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(boxmode\u001b[38;5;241m=\u001b[39mboxmode),\n\u001b[0;32m    671\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\plotly\\express\\_core.py:2090\u001b[0m, in \u001b[0;36mmake_figure\u001b[1;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[0;32m   2087\u001b[0m layout_patch \u001b[38;5;241m=\u001b[39m layout_patch \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m   2088\u001b[0m apply_default_cascade(args)\n\u001b[1;32m-> 2090\u001b[0m args \u001b[38;5;241m=\u001b[39m build_dataframe(args, constructor)\n\u001b[0;32m   2091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constructor \u001b[38;5;129;01min\u001b[39;00m [go\u001b[38;5;241m.\u001b[39mTreemap, go\u001b[38;5;241m.\u001b[39mSunburst, go\u001b[38;5;241m.\u001b[39mIcicle] \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2092\u001b[0m     args \u001b[38;5;241m=\u001b[39m process_dataframe_hierarchy(args)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\plotly\\express\\_core.py:1492\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[1;34m(args, constructor)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;66;03m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[39;00m\n\u001b[1;32m-> 1492\u001b[0m df_output, wide_id_vars \u001b[38;5;241m=\u001b[39m process_args_into_dataframe(\n\u001b[0;32m   1493\u001b[0m     args, wide_mode, var_name, value_name\n\u001b[0;32m   1494\u001b[0m )\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# now that `df_output` exists and `args` contains only references, we complete\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# the special-case and wide-mode handling by further rewriting args and/or mutating\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# df_output\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m count_name \u001b[38;5;241m=\u001b[39m _escape_col_name(df_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, [var_name, value_name])\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\plotly\\express\\_core.py:1213\u001b[0m, in \u001b[0;36mprocess_args_into_dataframe\u001b[1;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m argument \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1212\u001b[0m             err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m To use the index, pass it in directly as `df.index`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m length \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_input[argument]) \u001b[38;5;241m!=\u001b[39m length:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arguments should have the same length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of column argument `df[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]` is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, whereas the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1224\u001b[0m         )\n\u001b[0;32m   1225\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Value of 'y' is not the name of a column in 'data_frame'. Expected one of ['fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"'] but received: quality"
     ]
    }
   ],
   "source": [
    "#No tenemos duplicados, por ahora todo perfecto.\n",
    "#Ahora vamos a ver si tenemos outliers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(df, y='quality')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haré gráficos para ver como se comportan los datos\n",
    "fig = px.histogram(df, x='pH')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haré una correlación para ver cuales son los más influyentes para 'quality'\n",
    "correlation_matrix = df.corr(method = 'pearson')\n",
    "plt.figure(figsize = (12, 10))\n",
    "sns.heatmap(correlation_matrix, annot = True, cmap = 'coolwarm', center = 0)\n",
    "plt.title('Mapa de Calor de la Correlación de Pearson')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empezaremos el preprocesamiento manteniendo todas las columnas excepto ID y analizaré el rendimiento\n",
    "#Si veo que es muy bajo veo para eliminar algunas columnas\n",
    "df = df.drop(['Id'], axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X = df.drop(columns=['quality']) #Con esto selecciono todas las columnas, excepto quality\n",
    "y = df['quality'] #Esta es mi variable objetivo\n",
    "\n",
    "#Ahora divido el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Divido las características numéricas y categóricas\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Ahora hago el pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "#Ajusto ahora el pipeline a los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora empiezo con los modelos predictivos\n",
    "\n",
    "\n",
    "linear_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio LinearRegression: {mse}')\n",
    "print(f'R-cuadrado LinearRegression: {r2}')\n",
    "\n",
    "#Voy con otro modelo ahora\n",
    "#Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators = 100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio Random Forest: {mse}')\n",
    "print(f'R-cuadrado Random Forest: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esto tenemos que el RandomForest es el mejor para este caso porque presenta unos mejores\n",
    "#resultados, pero trataremos de mejorarlo\n",
    "#KNN\n",
    "\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio KNN: {mse}')\n",
    "print(f'R-cuadrado KNN: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigue siendo Random Forest el mejor\n",
    "#Utilizaré validación cruzada para seleccionar los mehores hiperparámetros\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Probar diferentes valores de K\n",
    "k_values = list(range(1, 21))\n",
    "mse_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    mse_scores.append(scores.mean())\n",
    "\n",
    "# Seleccionar el K con el menor MSE\n",
    "best_k = k_values[mse_scores.index(max(mse_scores))]\n",
    "print(f'Mejor valor de K: {best_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora voy a probar el modelo con la mejor k\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=15))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio KNN: {mse}')\n",
    "print(f'R-cuadrado KNN: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haré el árbol de decisión \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "tree_pipeline.fit(X_train, y_train)\n",
    "y_pred = tree_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio Decision Tree: {mse}')\n",
    "print(f'R-cuadrado Decision Tree: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigue siendo RandomForest el mejor\n",
    "#Trataré de mejorar el modelo eliminando algunas columnas primeramente \n",
    "df2 = df.drop(columns = ['residual sugar', 'free sulfur dioxide', 'pH'])\n",
    "\n",
    "#Ahora hago todo de nuevo\n",
    "X = df2.drop(columns=['quality']) #Con esto selecciono todas las columnas, excepto quality\n",
    "y = df2['quality'] #Esta es mi variable objetivo\n",
    "\n",
    "#Ahora divido el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Divido las características numéricas y categóricas\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Ahora hago el pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "#Ajusto ahora el pipeline a los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Ahora empiezo con los modelos predictivos\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "linear_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio LinearRegression: {mse}')\n",
    "print(f'R-cuadrado LinearRegression: {r2}')\n",
    "\n",
    "#Voy con otro modelo ahora\n",
    "#Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators = 100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio Random Forest: {mse}')\n",
    "print(f'R-cuadrado Random Forest: {r2}')\n",
    "\n",
    "#KNN\n",
    "\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio KNN: {mse}')\n",
    "print(f'R-cuadrado KNN: {r2}')\n",
    "\n",
    "# Probar diferentes valores de K\n",
    "k_values = list(range(1, 21))\n",
    "mse_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    mse_scores.append(scores.mean())\n",
    "\n",
    "# Seleccionar el K con el menor MSE\n",
    "best_k = k_values[mse_scores.index(max(mse_scores))]\n",
    "print(f'Mejor valor de K: {best_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora voy a probar el modelo con la mejor k\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=8))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio KNN: {mse}')\n",
    "print(f'R-cuadrado KNN: {r2}')\n",
    "\n",
    "#Haré el árbol de decisión \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "tree_pipeline.fit(X_train, y_train)\n",
    "y_pred = tree_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio Decision Tree: {mse}')\n",
    "print(f'R-cuadrado Decision Tree: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No consigo mejorar mucho haciendo esto, probaré eliminando outliers\n",
    "fig = px.box(df2, y='fixed acidity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[(df2['fixed acidity'] >= 4.6) & (df2['fixed acidity'] <= 12)]\n",
    "fig = px.box(df2, y='volatile acidity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[(df2['volatile acidity'] >= 0.12) & (df2['volatile acidity'] <= 1.005)]\n",
    "fig = px.box(df2, y='citric acid')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[(df2['citric acid'] >= 0) & (df2['citric acid'] <= 0.76)]\n",
    "fig = px.box(df2, y='chlorides')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estos son demasiados outliers, eliminaré demasiado datos si los elimino\n",
    "#Eliminaré solo los que están muy fuera\n",
    "df2 = df2[(df2['chlorides'] >= 0.012) & (df2['chlorides'] < 0.332)]\n",
    "fig = px.box(df2, y='total sulfur dioxide')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminaré solo los que están muy fuera\n",
    "df2 = df2[(df2['total sulfur dioxide'] >= 6) & (df2['total sulfur dioxide'] < 165)]\n",
    "fig = px.box(df2, y='density')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminaré solo los que están muy fuera\n",
    "df2 = df2[(df2['density'] >= 0.99154) & (df2['density'] < 1.001)]\n",
    "fig = px.box(df2, y='sulphates')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminaré solo los que están muy fuera\n",
    "df2 = df2[(df2['sulphates'] >= 0.33) & (df2['sulphates'] < 1.36)]\n",
    "fig = px.box(df2, y='alcohol')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[(df2['alcohol'] >= 8.5) & (df2['alcohol'] <= 13.4)]\n",
    "#Ahora vuelvo a hacer la prediccion\n",
    "X = df2.drop(columns=['quality']) #Con esto selecciono todas las columnas, excepto quality\n",
    "y = df2['quality'] #Esta es mi variable objetivo\n",
    "\n",
    "#Ahora divido el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Divido las características numéricas y categóricas\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Ahora hago el pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "#Ajusto ahora el pipeline a los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Ahora empiezo con los modelos predictivos\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "linear_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio LinearRegression: {mse}')\n",
    "print(f'R-cuadrado LinearRegression: {r2}')\n",
    "\n",
    "#Voy con otro modelo ahora\n",
    "#Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators = 100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio Random Forest: {mse}')\n",
    "print(f'R-cuadrado Random Forest: {r2}')\n",
    "\n",
    "#KNN\n",
    "\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio KNN: {mse}')\n",
    "print(f'R-cuadrado KNN: {r2}')\n",
    "\n",
    "# Probar diferentes valores de K\n",
    "k_values = list(range(1, 21))\n",
    "mse_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    mse_scores.append(scores.mean())\n",
    "\n",
    "# Seleccionar el K con el menor MSE\n",
    "best_k = k_values[mse_scores.index(max(mse_scores))]\n",
    "print(f'Mejor valor de K: {best_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora voy a probar el modelo con la mejor k\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=16))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio KNN: {mse}')\n",
    "print(f'R-cuadrado KNN: {r2}')\n",
    "\n",
    "#Haré el árbol de decisión \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "tree_pipeline.fit(X_train, y_train)\n",
    "y_pred = tree_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Error Cuadrático Medio Decision Tree: {mse}')\n",
    "print(f'R-cuadrado Decision Tree: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los outliers empeoró la predicción, así que me quedo con los outliers y elijo la mejor\n",
    "#que fue el randomForest del primer Dataset\n",
    "#Convertiré quality a una variable categórica\n",
    "df['quality'] = df['quality'].apply(lambda x: 1 if x >=6 else 0)\n",
    "\n",
    "#Con esto decimos que más o igual a 6 es alta calidad y menos es de baja calidad\n",
    "#Redefino los conjuntos de entrenamiento y prueba\n",
    "X = df.drop(columns=['quality'])\n",
    "y = df['quality']\n",
    "\n",
    "print(y.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Ya se que el random Forest es el mejor, usaré RandomForestClassifier\n",
    "\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Ahora hago el pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "rf_pipeline_best_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators = 100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline_best_model.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline_best_model.predict(X_test)\n",
    "\n",
    "#Ahora los evalúo en los modelos de clasificación\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred_rf = rf_pipeline_best_model.predict(X_test)\n",
    "\n",
    "#Calculo las metricas de clasificación\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "#Generar el informe de clasificacion\n",
    "report = classification_report(y_test, y_pred_rf)\n",
    "print(report)\n",
    "\n",
    "#Hago la matriz de confusión\n",
    "print(f'La matriz de confusión para Random Forest es:')\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
